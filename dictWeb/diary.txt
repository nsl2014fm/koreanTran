#coding=utf-8
##===============2016/05/05=========================
任务:爬取hj，翻译韩语，提取中文翻译
任务量：待翻译词汇量达百万
框架：无

面临问题：1.数据量太大，爬虫访问过于频繁，容易被目标站点查封
         2.程序需放到服务器上运行，不熟悉linux系统操作

解决方案：1.（1）设置爬取频率，尽量不被目标站点查封
            （2）写日志文件，程序出错时，能从上次错误点断点继续进行
            （3）改写程序：读入待翻译词汇，保存网页，删除已查询词汇，设置爬虫出错自动重启继续执行。
         2.没办法，现学linux操作

对于问题1，（1）（3）结合是比较好的方法

